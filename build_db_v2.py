import os
import pdfplumber
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# --- é…ç½®è·¯å¾„ ---
DATA_PATH = "./data"
DB_PATH = "./chroma_db_pro"


def load_pdf_visual_layout(pdf_path):
    print(f"ğŸ“– æ­£åœ¨æŒ‰ã€è§†è§‰å¸ƒå±€ã€‘è§£æ: {os.path.basename(pdf_path)} ...")
    documents = []

    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages):
            # âœ… æ ¸å¿ƒï¼šä½¿ç”¨ layout=True ä¿ç•™è¡¨æ ¼çš„ç‰©ç†å¯¹é½æ ¼å¼
            # è¿™æ · AI å°±èƒ½åƒäººçœ¼ä¸€æ ·ï¼Œé€šè¿‡ç©ºæ ¼ä½ç½®çœ‹å‡ºè°å¯¹åº”è°
            text = page.extract_text(layout=True) or ""

            metadata = {"source": pdf_path, "page": i + 1}
            documents.append(Document(page_content=text, metadata=metadata))

    return documents


def create_vector_db_pro():
    pdf_files = [f for f in os.listdir(DATA_PATH) if f.endswith(".pdf")]
    if not pdf_files:
        print("âŒ data æ–‡ä»¶å¤¹æ˜¯ç©ºçš„ï¼")
        return

    all_docs = []
    for pdf_file in pdf_files:
        path = os.path.join(DATA_PATH, pdf_file)
        docs = load_pdf_visual_layout(path)
        all_docs.extend(docs)

    print(f"âœ… è§£æå®Œæˆï¼Œå…± {len(all_docs)} é¡µã€‚")

    # ç¡®ä¿æ•´æ•´ä¸€é¡µï¼ˆç”šè‡³ä¸¤é¡µï¼‰éƒ½åœ¨åŒä¸€ä¸ªç‰‡æ®µé‡Œï¼Œç»ä¸åˆ‡æ–­è¡¨æ ¼ã€‚
    # --- ğŸ”´ æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šæ”¹å›å°çª—å£ ---
    # è¿™æ ·è¡¨æ ¼çš„æ¯ä¸€è¡Œéƒ½ä¼šå˜æˆä¸€ä¸ªç‹¬ç«‹çš„ã€é«˜æƒé‡çš„ç‰‡æ®µ
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=600,
        chunk_overlap=50,
        separators=["\n", " ", ""]  # ä¼˜å…ˆæŒ‰è¡Œåˆ‡ï¼Œä¿æŠ¤è¡¨æ ¼è¡Œ
    )

    splits = text_splitter.split_documents(all_docs)
    print(f"âœ‚ï¸ å…±åˆ‡åˆ†ä¸º {len(splits)} ä¸ªç‰‡æ®µ (æ•°é‡åº”è¯¥ä¼šå˜å¤š)")
    print("ğŸ§  æ­£åœ¨é‡å»ºæ•°æ®åº“...")
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    vector_db = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
        persist_directory=DB_PATH
    )
    print(f"ğŸ‰ è§†è§‰å¸ƒå±€ç‰ˆæ•°æ®åº“æ„å»ºæˆåŠŸï¼å·²ä¿å­˜åˆ° {DB_PATH}")


if __name__ == "__main__":
    create_vector_db_pro()